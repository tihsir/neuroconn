{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing and applying a linear minimum-norm inverse method on evoked/raw/epochs data\n",
    "\n",
    "# Import necessary libraries and functions\n",
    "from mne.minimum_norm import apply_inverse_epochs\n",
    "from mne.minimum_norm import make_inverse_operator, apply_inverse\n",
    "from mne.datasets import sample, eegbci, fetch_fsaverage\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as op\n",
    "import numpy as np\n",
    "import matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pyvistaqt 3d backend.\n",
      "\n",
      "0 files missing from root.txt in /home/prakhar/mne_data/MNE-fsaverage-data\n",
      "0 files missing from bem.txt in /home/prakhar/mne_data/MNE-fsaverage-data/fsaverage\n",
      "Reading /home/prakhar/code/uiuc/mfprl/neuroconn/src/../data/in/101_epoched.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -500.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "58 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "EEG channel type selected for re-referencing\n",
      "Adding average EEG reference projection.\n",
      "1 projection items deactivated\n",
      "Average reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\n",
      "Reading /home/prakhar/mne_data/MNE-fsaverage-data/fsaverage/bem/fsaverage-ico-5-src.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43741/404698301.py:26: RuntimeWarning: This filename (../data/in/101_epoched.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  epochs = mne.read_epochs(epoched_file)\n",
      "/tmp/ipykernel_43741/404698301.py:38: RuntimeWarning: Fiducial point nasion not found, assuming identity unknown to head transformation\n",
      "  epochs.set_montage(montage)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For automatic theme detection, \"darkdetect\" has to be installed! You can install it with `pip install darkdetect`\n",
      "For automatic theme detection, \"darkdetect\" has to be installed! You can install it with `pip install darkdetect`\n",
      "To use light mode, \"qdarkstyle\" has to be installed! You can install it with:\n",
      "pip install qdarkstyle\n",
      "\n",
      "Using outer_skin.surf for head surface.\n",
      "Channel types::\teeg: 57\n",
      "Projecting sensors to the head surface\n",
      "Source space          : /home/prakhar/mne_data/MNE-fsaverage-data/fsaverage/bem/fsaverage-ico-5-src.fif\n",
      "MRI -> head transform : /home/prakhar/.local/lib/python3.10/site-packages/mne/data/fsaverage/fsaverage-trans.fif\n",
      "Measurement data      : instance of Info\n",
      "Conductor model   : /home/prakhar/mne_data/MNE-fsaverage-data/fsaverage/bem/fsaverage-5120-5120-5120-bem-sol.fif\n",
      "Accurate field computations\n",
      "Do computations in head coordinates\n",
      "Free source orientations\n",
      "\n",
      "Reading /home/prakhar/mne_data/MNE-fsaverage-data/fsaverage/bem/fsaverage-ico-5-src.fif...\n",
      "Read 2 source spaces a total of 20484 active source locations\n",
      "\n",
      "Coordinate transformation: MRI (surface RAS) -> head\n",
      "     0.999994  0.003552  0.000202      -1.76 mm\n",
      "    -0.003558  0.998389  0.056626      31.09 mm\n",
      "    -0.000001 -0.056626  0.998395      39.60 mm\n",
      "     0.000000  0.000000  0.000000       1.00\n",
      "\n",
      "Read  57 EEG channels from info\n",
      "Head coordinate coil definitions created.\n",
      "Source spaces are now in head coordinates.\n",
      "\n",
      "Setting up the BEM model using /home/prakhar/mne_data/MNE-fsaverage-data/fsaverage/bem/fsaverage-5120-5120-5120-bem-sol.fif...\n",
      "\n",
      "Loading surfaces...\n",
      "\n",
      "Loading the solution matrix...\n",
      "\n",
      "Three-layer model surfaces loaded.\n",
      "Loaded linear collocation BEM solution from /home/prakhar/mne_data/MNE-fsaverage-data/fsaverage/bem/fsaverage-5120-5120-5120-bem-sol.fif\n",
      "Employing the head->MRI coordinate transform with the BEM model.\n",
      "BEM model fsaverage-5120-5120-5120-bem-sol.fif is now set up\n",
      "\n",
      "Source spaces are in head coordinates.\n",
      "Checking that the sources are inside the surface and at least    5.0 mm away (will take a few...)\n",
      "Checking surface interior status for 10242 points...\n",
      "    Found  2433/10242 points inside  an interior sphere of radius   47.7 mm\n",
      "    Found     0/10242 points outside an exterior sphere of radius   98.3 mm\n",
      "    Found     0/ 7809 points outside using surface Qhull\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found     0/ 7809 points outside using solid angles\n",
      "    Total 10242/10242 points inside the surface\n",
      "Interior check completed in 5949.8 ms\n",
      "Checking surface interior status for 10242 points...\n",
      "    Found  2241/10242 points inside  an interior sphere of radius   47.7 mm\n",
      "    Found     0/10242 points outside an exterior sphere of radius   98.3 mm\n",
      "    Found     0/ 8001 points outside using surface Qhull\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found     0/ 8001 points outside using solid angles\n",
      "    Total 10242/10242 points inside the surface\n",
      "Interior check completed in 6061.8 ms\n",
      "\n",
      "Setting up for EEG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing EEG at 20484 source locations (free orientations)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 2.8e-11 (2.2e-16 eps * 57 dim * 2.2e+03  max singular value)\n",
      "    Estimated rank (eeg): 56\n",
      "    EEG: rank 56 computed from 57 data channels with 1 projector\n",
      "    Created an SSP operator (subspace dimension = 1)\n",
      "    Setting small EEG eigenvalues to zero (without PCA)\n",
      "Reducing data rank from 57 -> 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    8.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    8.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating covariance using SHRUNK\n",
      "Done.\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Using cross-validation to select the best estimator.\n",
      "Number of samples used : 14906\n",
      "log-likelihood on unseen data (descending order):\n",
      "   shrunk: -52.425\n",
      "   empirical: -346.184\n",
      "selecting best estimator: shrunk\n",
      "[done]\n",
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 4.1e-14 (2.2e-16 eps * 57 dim * 3.2  max singular value)\n",
      "    Estimated rank (eeg): 56\n",
      "    EEG: rank 56 computed from 57 data channels with 0 projectors\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/prakhar/code/uiuc/mfprl/neuroconn/src/source_localization.ipynb Cell 2\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/prakhar/code/uiuc/mfprl/neuroconn/src/source_localization.ipynb#W1sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m \u001b[39m# Compute regularized noise covariance\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/prakhar/code/uiuc/mfprl/neuroconn/src/source_localization.ipynb#W1sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m noise_cov \u001b[39m=\u001b[39m mne\u001b[39m.\u001b[39mcompute_covariance(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/prakhar/code/uiuc/mfprl/neuroconn/src/source_localization.ipynb#W1sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m     epochs, tmax\u001b[39m=\u001b[39m\u001b[39m0.0\u001b[39m, method\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mshrunk\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mempirical\u001b[39m\u001b[39m\"\u001b[39m], rank\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/prakhar/code/uiuc/mfprl/neuroconn/src/source_localization.ipynb#W1sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/prakhar/code/uiuc/mfprl/neuroconn/src/source_localization.ipynb#W1sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m fig_cov, fig_spectra \u001b[39m=\u001b[39m mne\u001b[39m.\u001b[39;49mviz\u001b[39m.\u001b[39;49mplot_cov(noise_cov, epochs\u001b[39m.\u001b[39;49minfo)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/prakhar/code/uiuc/mfprl/neuroconn/src/source_localization.ipynb#W1sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m \u001b[39m#################################################################################\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/prakhar/code/uiuc/mfprl/neuroconn/src/source_localization.ipynb#W1sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m \u001b[39m# Visualize the source space on the cortex\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/prakhar/code/uiuc/mfprl/neuroconn/src/source_localization.ipynb#W1sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/prakhar/code/uiuc/mfprl/neuroconn/src/source_localization.ipynb#W1sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m \u001b[39m# Read the forward solution\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/prakhar/code/uiuc/mfprl/neuroconn/src/source_localization.ipynb#W1sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m mne\u001b[39m.\u001b[39mconvert_forward_solution(fwd, surf_ori\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m<decorator-gen-157>:12\u001b[0m, in \u001b[0;36mplot_cov\u001b[0;34m(cov, info, exclude, colorbar, proj, show_svd, show, verbose)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/mne/viz/misc.py:233\u001b[0m, in \u001b[0;36mplot_cov\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    224\u001b[0m         axes[\u001b[39m0\u001b[39m, k]\u001b[39m.\u001b[39mset(\n\u001b[1;32m    225\u001b[0m             ylabel\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNoise Ïƒ (\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m unit,\n\u001b[1;32m    226\u001b[0m             yscale\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlog\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    229\u001b[0m             xlim\u001b[39m=\u001b[39m[\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(s) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m],\n\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m     tight_layout(fig\u001b[39m=\u001b[39mfig_svd)\n\u001b[0;32m--> 233\u001b[0m plt_show(show)\n\u001b[1;32m    235\u001b[0m \u001b[39mreturn\u001b[39;00m fig_cov, fig_svd\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/mne/viz/utils.py:161\u001b[0m, in \u001b[0;36mplt_show\u001b[0;34m(show, fig, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[39mif\u001b[39;00m show \u001b[39mand\u001b[39;00m backend \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39magg\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    160\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mShowing plot for backend \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(backend)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 161\u001b[0m     (fig \u001b[39mor\u001b[39;49;00m plt)\u001b[39m.\u001b[39;49mshow(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/pyplot.py:421\u001b[0m, in \u001b[0;36mshow\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    378\u001b[0m \u001b[39mDisplay all open figures.\u001b[39;00m\n\u001b[1;32m    379\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[39mexplicitly there.\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    420\u001b[0m _warn_if_gui_out_of_main_thread()\n\u001b[0;32m--> 421\u001b[0m \u001b[39mreturn\u001b[39;00m _get_backend_mod()\u001b[39m.\u001b[39;49mshow(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/backend_bases.py:3546\u001b[0m, in \u001b[0;36m_Backend.show\u001b[0;34m(cls, block)\u001b[0m\n\u001b[1;32m   3544\u001b[0m     block \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m ipython_pylab \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_interactive()\n\u001b[1;32m   3545\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[0;32m-> 3546\u001b[0m     \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mmainloop()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/backends/backend_qt.py:1021\u001b[0m, in \u001b[0;36m_BackendQT.mainloop\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m   1019\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmainloop\u001b[39m():\n\u001b[1;32m   1020\u001b[0m     qapp \u001b[39m=\u001b[39m QtWidgets\u001b[39m.\u001b[39mQApplication\u001b[39m.\u001b[39minstance()\n\u001b[0;32m-> 1021\u001b[0m     \u001b[39mwith\u001b[39;00m _maybe_allow_interrupt(qapp):\n\u001b[1;32m   1022\u001b[0m         qt_compat\u001b[39m.\u001b[39m_exec(qapp)\n",
      "File \u001b[0;32m/usr/lib/python3.10/contextlib.py:142\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    141\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 142\u001b[0m         \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen)\n\u001b[1;32m    143\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/backends/qt_compat.py:269\u001b[0m, in \u001b[0;36m_maybe_allow_interrupt\u001b[0;34m(qapp)\u001b[0m\n\u001b[1;32m    267\u001b[0m signal\u001b[39m.\u001b[39msignal(signal\u001b[39m.\u001b[39mSIGINT, old_sigint_handler)\n\u001b[1;32m    268\u001b[0m \u001b[39mif\u001b[39;00m handler_args \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 269\u001b[0m     old_sigint_handler(\u001b[39m*\u001b[39;49mhandler_args)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "matplotlib.use('Qt5Agg')  # Setting the backend BEFORE importing pyplot\n",
    "\n",
    "mne.viz.set_3d_backend(\"pyvista\")\n",
    "\n",
    "#################################################################################\n",
    "# Adult template MRI (fsaverage)\n",
    "\n",
    "# Download fsaverage files\n",
    "fs_dir = fetch_fsaverage(verbose=True)\n",
    "subjects_dir = op.dirname(fs_dir)\n",
    "\n",
    "# The files live in:\n",
    "subject = \"fsaverage\"\n",
    "trans = \"fsaverage\"  # MNE has a built-in fsaverage transformation\n",
    "src = op.join(fs_dir, \"bem\", \"fsaverage-ico-5-src.fif\")\n",
    "bem = op.join(fs_dir, \"bem\", \"fsaverage-5120-5120-5120-bem-sol.fif\")\n",
    "\n",
    "#################################################################################\n",
    "\n",
    "# Process EEG data\n",
    "\n",
    "# Load epoched data\n",
    "output_dir = r'../data/in'  # Replace with your desired output directory\n",
    "subj = '101'  # --> replace participant ID here\n",
    "epoched_file = os.path.join(output_dir, subj + '_epoched.fif')\n",
    "epochs = mne.read_epochs(epoched_file)\n",
    "\n",
    "# List of channels to drop\n",
    "channels_to_drop = ['LHEye', 'RHEye', 'Lneck', 'Rneck', 'RVEye', 'FPz']\n",
    "\n",
    "# Drop the channels from the epochs data\n",
    "epochs.drop_channels(channels_to_drop)\n",
    "\n",
    "# Adjust EEG electrode locations to match the fsaverage template, which are already in fsaverage's\n",
    "# # space (MNI space) for standard_1020\n",
    "montage_path = r\"../data/in/MFPRL_UPDATED_V2.sfp\"\n",
    "montage = mne.channels.read_custom_montage(montage_path)\n",
    "epochs.set_montage(montage)\n",
    "epochs.set_eeg_reference(projection=True)  # needed for inverse modeling\n",
    "\n",
    "# Set the 3D backend to pyvista\n",
    "mne.viz.set_3d_backend(\"pyvista\")\n",
    "\n",
    "# Check that the locations of EEG electrodes is correct with respect to MRI\n",
    "mne.viz.plot_alignment(\n",
    "    epochs.info,\n",
    "    src=src,\n",
    "    eeg=[\"original\", \"projected\"],\n",
    "    trans=trans,\n",
    "    show_axes=True,\n",
    "    mri_fiducials=True,\n",
    "    dig=\"fiducials\",\n",
    ")\n",
    "\n",
    "# Compute the forward solution using the fsaverage template\n",
    "fwd = mne.make_forward_solution(\n",
    "    epochs.info, trans=trans, src=src, bem=bem, eeg=True, mindist=5.0, n_jobs=None\n",
    ")\n",
    "\n",
    "# Adjusting picks to EEG data\n",
    "picks = mne.pick_types(epochs.info, meg=False, eeg=True, eog=True, stim=False)\n",
    "\n",
    "# Compute regularized noise covariance\n",
    "noise_cov = mne.compute_covariance(\n",
    "    epochs, tmax=0.0, method=[\"shrunk\", \"empirical\"], rank=None, verbose=True\n",
    ")\n",
    "\n",
    "fig_cov, fig_spectra = mne.viz.plot_cov(noise_cov, epochs.info)\n",
    "\n",
    "#################################################################################\n",
    "# Visualize the source space on the cortex\n",
    "\n",
    "# Read the forward solution\n",
    "mne.convert_forward_solution(fwd, surf_ori=True, copy=False)\n",
    "\n",
    "# Extract the source space information from the forward solution\n",
    "lh = fwd[\"src\"][0]  # Visualize the left hemisphere\n",
    "verts = lh[\"rr\"]  # The vertices of the source space\n",
    "tris = lh[\"tris\"]  # Groups of three vertices that form triangles\n",
    "dip_pos = lh[\"rr\"][lh[\"vertno\"]]  # The position of the dipoles\n",
    "dip_ori = lh[\"nn\"][lh[\"vertno\"]]\n",
    "dip_len = len(dip_pos)\n",
    "dip_times = [0]\n",
    "\n",
    "# Create a Dipole instance\n",
    "actual_amp = np.ones(dip_len)  # misc amp to create Dipole instance\n",
    "actual_gof = np.ones(dip_len)  # misc GOF to create Dipole instance\n",
    "dipoles = mne.Dipole(dip_times, dip_pos, actual_amp, dip_ori, actual_gof)\n",
    "trans = trans\n",
    "\n",
    "# Create a new 3D figure and plot red dots at the dipole locations (run all code below at once)\n",
    "fig = mne.viz.create_3d_figure(size=(600, 400))\n",
    "mne.viz.plot_alignment(  # Plot the cortical surface on the figure\n",
    "    subject=subject,\n",
    "    subjects_dir=subjects_dir,\n",
    "    trans=trans,\n",
    "    surfaces=\"white\",\n",
    "    coord_frame=\"mri\",\n",
    "    fig=fig,\n",
    ")\n",
    "mne.viz.plot_dipole_locations(  # Plot the dipoles on the same figure\n",
    "    dipoles=dipoles,\n",
    "    trans=trans,\n",
    "    mode=\"sphere\",\n",
    "    subject=subject,\n",
    "    subjects_dir=subjects_dir,\n",
    "    coord_frame=\"mri\",\n",
    "    scale=7e-4,\n",
    "    fig=fig,\n",
    ")\n",
    "mne.viz.set_3d_view(figure=fig, azimuth=180, distance=0.25)  # Adjust the view\n",
    "\n",
    "# Save the computed forward solution to a .fif file\n",
    "output_dir = r'../data/out'  # Replace with your desired output directory\n",
    "forward_solution_file = os.path.join(\n",
    "    output_dir, subj + '_forwardsolution_MRItemplate.fif')\n",
    "mne.write_forward_solution(forward_solution_file, fwd, overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting forward solution to surface orientation\n",
      "    No patch info available. The standard source space normals will be employed in the rotation to the local surface coordinates....\n",
      "    Converting to surface-based source orientations...\n",
      "    [done]\n",
      "Computing inverse operator with 57 channels.\n",
      "    57 out of 57 channels remain after picking\n",
      "Selected 57 channels\n",
      "Creating the depth weighting matrix...\n",
      "    57 EEG channels\n",
      "    limit = 20485/20484 = 2.125736\n",
      "    scale = 134832 exp = 0.8\n",
      "Applying loose dipole orientations to surface source spaces: 0.2\n",
      "Whitening the forward solution.\n",
      "    Created an SSP operator (subspace dimension = 1)\n",
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 4.1e-14 (2.2e-16 eps * 57 dim * 3.2  max singular value)\n",
      "    Estimated rank (eeg): 56\n",
      "    EEG: rank 56 computed from 57 data channels with 1 projector\n",
      "    Setting small EEG eigenvalues to zero (without PCA)\n",
      "Creating the source covariance matrix\n",
      "Adjusting source covariance matrix.\n",
      "Computing SVD of whitened and weighted lead field matrix.\n",
      "    largest singular value = 7.05008\n",
      "    scaling factor to adjust the trace = 3.97546e+24 (nchan = 57 nzero = 1)\n",
      "Preparing the inverse operator for use...\n",
      "    Scaled noise and source covariance from nave = 1 to nave = 1\n",
      "    Created the regularized inverter\n",
      "    Created an SSP operator (subspace dimension = 1)\n",
      "    Created the whitener using a noise covariance matrix with rank 56 (1 small eigenvalues omitted)\n",
      "    Computing optimized source covariance (eLORETA)...\n",
      "        Using independent orientation weights\n",
      "        Fitting up to 20 iterations (this make take a while)...\n",
      "        Converged on iteration 8 (7.4e-07 < 1e-06)\n",
      "        Updating inverse with weighted eigen leads\n",
      "[done]\n",
      "Picked 57 channels from the data\n",
      "Computing inverse...\n",
      "    Eigenleads already weighted ... \n",
      "Processing epoch : 1 / 58\n",
      "combining the current components...\n",
      "Processing epoch : 2 / 58\n",
      "combining the current components...\n",
      "Processing epoch : 3 / 58\n",
      "combining the current components...\n",
      "Processing epoch : 4 / 58\n",
      "combining the current components...\n",
      "Processing epoch : 5 / 58\n",
      "combining the current components...\n",
      "Processing epoch : 6 / 58\n",
      "combining the current components...\n",
      "Processing epoch : 7 / 58\n",
      "combining the current components...\n",
      "Processing epoch : 8 / 58\n",
      "combining the current components...\n",
      "Processing epoch : 9 / 58\n",
      "combining the current components...\n",
      "Processing epoch : 10 / 58\n",
      "combining the current components...\n",
      "Processing epoch : 11 / 58\n",
      "combining the current components...\n",
      "Processing epoch : 12 / 58\n",
      "combining the current components...\n",
      "Processing epoch : 13 / 58\n",
      "combining the current components...\n",
      "Processing epoch : 14 / 58\n",
      "combining the current components...\n",
      "Processing epoch : 15 / 58\n",
      "combining the current components...\n",
      "Processing epoch : 16 / 58\n",
      "combining the current components...\n",
      "Processing epoch : 17 / 58\n",
      "combining the current components...\n",
      "Processing epoch : 18 / 58\n",
      "combining the current components...\n",
      "Processing epoch : 19 / 58\n",
      "combining the current components...\n",
      "Processing epoch : 20 / 58\n",
      "combining the current components...\n",
      "Processing epoch : 21 / 58\n",
      "combining the current components...\n",
      "Processing epoch : 22 / 58\n",
      "combining the current components...\n",
      "Processing epoch : 23 / 58\n",
      "combining the current components...\n",
      "Processing epoch : 24 / 58\n",
      "combining the current components...\n",
      "Processing epoch : 25 / 58\n",
      "combining the current components...\n",
      "Processing epoch : 26 / 58\n",
      "combining the current components...\n",
      "Processing epoch : 27 / 58\n",
      "combining the current components...\n",
      "Processing epoch : 28 / 58\n",
      "combining the current components...\n",
      "Processing epoch : 29 / 58\n",
      "combining the current components...\n",
      "Processing epoch : 30 / 58\n",
      "combining the current components...\n",
      "Processing epoch : 31 / 58\n",
      "combining the current components...\n",
      "Processing epoch : 32 / 58\n",
      "combining the current components...\n",
      "Processing epoch : 33 / 58\n",
      "combining the current components...\n",
      "Processing epoch : 34 / 58\n",
      "combining the current components...\n",
      "Processing epoch : 35 / 58\n",
      "combining the current components...\n",
      "Processing epoch : 36 / 58\n",
      "combining the current components...\n",
      "Processing epoch : 37 / 58\n",
      "combining the current components...\n",
      "Processing epoch : 38 / 58\n",
      "combining the current components...\n",
      "Processing epoch : 39 / 58\n",
      "combining the current components...\n",
      "Processing epoch : 40 / 58\n",
      "combining the current components...\n",
      "Processing epoch : 41 / 58\n",
      "combining the current components...\n",
      "Processing epoch : 42 / 58\n",
      "combining the current components...\n",
      "Processing epoch : 43 / 58\n",
      "combining the current components...\n",
      "Processing epoch : 44 / 58\n",
      "combining the current components...\n",
      "Processing epoch : 45 / 58\n",
      "combining the current components...\n",
      "Processing epoch : 46 / 58\n",
      "combining the current components...\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#################################################################################\n",
    "# Inverse modeling: eLORETA on evoked data with dipole orientation discarded (pick_ori=\"None\"), only magnitude kept\n",
    "\n",
    "\n",
    "# Create a loose-orientation inverse operator, with depth weighting\n",
    "inv = make_inverse_operator(\n",
    "    epochs.info, fwd, noise_cov, fixed=False, loose=0.2, depth=0.8, verbose=True)\n",
    "\n",
    "# Compute eLORETA solution for each epoch\n",
    "snr = 3.0\n",
    "lambda2 = 1.0 / snr**2\n",
    "# pick_ori=\"None\" --> Discard dipole orientation, only keep magnitude\n",
    "stcs = apply_inverse_epochs(\n",
    "    epochs, inv, lambda2, \"eLORETA\", verbose=True, pick_ori=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average the source estimates across epochs\n",
    "stc_avg = sum(stcs) / len(stcs)\n",
    "\n",
    "# Get the time of the peak magnitude\n",
    "print(stcs[0])\n",
    "_, time_max = stc_avg.magnitude().get_peak(hemi=\"lh\")\n",
    "\n",
    "# Visualization parameters\n",
    "kwargs = dict(\n",
    "    hemi=\"lh\",\n",
    "    subjects_dir=subjects_dir,\n",
    "    size=(600, 600),\n",
    "    clim=dict(kind=\"percent\", lims=[90, 95, 99]),\n",
    "    smoothing_steps=7,\n",
    "    time_unit=\"s\",\n",
    "    initial_time=time_max  # Set the initial_time to the time of the peak magnitude\n",
    ")\n",
    "\n",
    "# Visualizing the averaged source estimate with dipole magnitude\n",
    "brain_magnitude = stc_avg.plot(**kwargs)\n",
    "mne.viz.set_3d_view(figure=brain_magnitude, focalpoint=(0.0, 0.0, 50))\n",
    "\n",
    "# Average the data across all source space points\n",
    "avg_data = stc_avg.data.mean(axis=(0, 1))\n",
    "\n",
    "# Plot the average data as a function of time\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(1e3 * stc_avg.times, avg_data)\n",
    "ax.set(xlabel=\"time (ms)\", ylabel=\"eLORETA value (average)\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print('Saving file')\n",
    "# Save the inverse solution data\n",
    "output_dir = r'../data/out'  # Replace with your desired output directory\n",
    "for idx, stc in enumerate(stcs):\n",
    "    inverse_solution_file = os.path.join(\n",
    "        output_dir, f\"{subj}_inversesolution_epoch{idx}.fif\")\n",
    "    stc.save(inverse_solution_file, overwrite=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
